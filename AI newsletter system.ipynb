{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b51c2d1-5990-4516-b5a5-900939d8a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in c:\\users\\mansi\\anaconda3\\lib\\site-packages (6.0.11)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in c:\\users\\mansi\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mansi\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\mansi\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install feedparser nltk scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac818704-1b42-464c-93fd-1e316e8c40c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating newsletter for Alex Parker...\n",
      "Newsletter saved to newsletters/alex_parker_newsletter.md\n",
      "Generating newsletter for Priya Sharma...\n",
      "Newsletter saved to newsletters/priya_sharma_newsletter.md\n",
      "Generating newsletter for Marco Rossi...\n",
      "Newsletter saved to newsletters/marco_rossi_newsletter.md\n",
      "Generating newsletter for Lisa Thompson...\n",
      "Newsletter saved to newsletters/lisa_thompson_newsletter.md\n",
      "Generating newsletter for David Martinez...\n",
      "Newsletter saved to newsletters/david_martinez_newsletter.md\n",
      "\n",
      "==================================================\n",
      "Newsletters are saved at: C:\\Users\\MANSI\\newsletters\n",
      "You can open this directory to view the generated newsletters.\n",
      "==================================================\n",
      "\n",
      "An index.html file has been created in the newsletters directory.\n",
      "You can open this file in a web browser to easily access all newsletters.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI-Powered Personalized Newsletter Generator\n",
    "\n",
    "This script fetches articles from RSS feeds, categorizes them using NLP,\n",
    "and generates personalized newsletters based on user preferences.\n",
    "\"\"\"\n",
    "\n",
    "import feedparser\n",
    "import nltk\n",
    "import datetime\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "class RSSFeedReader:\n",
    "    \"\"\"Handles fetching and parsing RSS feeds.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feeds = {\n",
    "            'general': [\n",
    "                'http://feeds.bbci.co.uk/news/world/rss.xml',\n",
    "                'https://rss.nytimes.com/services/xml/rss/nyt/World.xml',\n",
    "                'https://www.reuters.com/rss/world'\n",
    "            ],\n",
    "            'technology': [\n",
    "                'https://techcrunch.com/feed/',\n",
    "                'https://www.wired.com/feed/rss',\n",
    "                'https://www.technologyreview.com/feed/'\n",
    "            ],\n",
    "            'finance': [\n",
    "                'https://www.bloomberg.com/feed/podcast/etf-report',\n",
    "                'https://www.cnbc.com/id/10001147/device/rss/rss.html',\n",
    "                'https://www.ft.com/rss/home'\n",
    "            ],\n",
    "            'sports': [\n",
    "                'https://www.espn.com/espn/rss/news',\n",
    "                'http://feeds.bbci.co.uk/sport/rss.xml',\n",
    "                'https://www.skysports.com/rss/0'\n",
    "            ],\n",
    "            'entertainment': [\n",
    "                'https://variety.com/feed/',\n",
    "                'https://www.hollywoodreporter.com/feed/',\n",
    "                'https://www.billboard.com/feed/'\n",
    "            ],\n",
    "            'science': [\n",
    "                'https://www.nasa.gov/rss/dyn/breaking_news.rss',\n",
    "                'https://www.sciencedaily.com/rss/all.xml',\n",
    "                'https://arstechnica.com/science/feed/'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def fetch_articles(self, categories=None, max_articles_per_feed=5):\n",
    "        \"\"\"\n",
    "        Fetches articles from RSS feeds.\n",
    "        \n",
    "        Args:\n",
    "            categories: List of categories to fetch articles from. If None, fetch from all categories.\n",
    "            max_articles_per_feed: Maximum number of articles to fetch from each feed.\n",
    "            \n",
    "        Returns:\n",
    "            List of articles, each being a dictionary with keys: title, link, summary, source, category.\n",
    "        \"\"\"\n",
    "        if categories is None:\n",
    "            categories = list(self.feeds.keys())\n",
    "        \n",
    "        articles = []\n",
    "        \n",
    "        for category in categories:\n",
    "            if category not in self.feeds:\n",
    "                continue\n",
    "                \n",
    "            for feed_url in self.feeds[category]:\n",
    "                try:\n",
    "                    # Parse the feed\n",
    "                    feed = feedparser.parse(feed_url)\n",
    "                    \n",
    "                    # Extract feed name from boilerplate\n",
    "                    feed_name = feed.feed.get('title', feed_url)\n",
    "                    \n",
    "                    # Get articles\n",
    "                    for i, entry in enumerate(feed.entries):\n",
    "                        if i >= max_articles_per_feed:\n",
    "                            break\n",
    "                            \n",
    "                        # Extract article information\n",
    "                        article = {\n",
    "                            'title': entry.get('title', 'No title'),\n",
    "                            'link': entry.get('link', ''),\n",
    "                            'summary': entry.get('summary', entry.get('description', 'No summary available')),\n",
    "                            'source': feed_name,\n",
    "                            'category': category,\n",
    "                            'published': entry.get('published', datetime.datetime.now().strftime('%Y-%m-%d')),\n",
    "                        }\n",
    "                        \n",
    "                        articles.append(article)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching from {feed_url}: {e}\")\n",
    "        \n",
    "        return articles\n",
    "\n",
    "class ArticleAnalyzer:\n",
    "    \"\"\"Uses NLP to analyze and categorize articles.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocesses text for NLP analysis.\"\"\"\n",
    "        # Convert to lowercase and tokenize\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Remove stopwords and non-alphabetic tokens\n",
    "        filtered_tokens = [token for token in tokens if token.isalpha() and token not in self.stop_words]\n",
    "        \n",
    "        return ' '.join(filtered_tokens)\n",
    "    \n",
    "    def extract_keywords(self, text, num_keywords=5):\n",
    "        \"\"\"Extracts the most significant keywords from text.\"\"\"\n",
    "        processed_text = self.preprocess_text(text)\n",
    "        \n",
    "        # Create a document-term matrix\n",
    "        tfidf_matrix = self.vectorizer.fit_transform([processed_text])\n",
    "        \n",
    "        # Get feature names (terms)\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get scores for each term\n",
    "        scores = zip(feature_names, tfidf_matrix.toarray()[0])\n",
    "        \n",
    "        # Sort terms by score and get top keywords\n",
    "        sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [keyword for keyword, score in sorted_scores[:num_keywords]]\n",
    "    \n",
    "    def calculate_relevance_score(self, article, user_interests):\n",
    "        \"\"\"\n",
    "        Calculates relevance score of an article to user interests.\n",
    "        \n",
    "        Args:\n",
    "            article: Dictionary containing article information\n",
    "            user_interests: List of user interest keywords\n",
    "            \n",
    "        Returns:\n",
    "            Float between 0 and 1 indicating relevance\n",
    "        \"\"\"\n",
    "        # Combine title and summary for analysis\n",
    "        article_text = article['title'] + ' ' + article['summary']\n",
    "        article_text = self.preprocess_text(article_text)\n",
    "        \n",
    "        # Extract keywords from the article\n",
    "        article_keywords = self.extract_keywords(article_text, num_keywords=10)\n",
    "        \n",
    "        # Calculate overlap between article keywords and user interests\n",
    "        matching_keywords = sum(1 for keyword in article_keywords if any(interest.lower() in keyword.lower() for interest in user_interests))\n",
    "        \n",
    "        # Calculate a relevance score (0 to 1)\n",
    "        if not article_keywords:\n",
    "            return 0\n",
    "        \n",
    "        return matching_keywords / len(article_keywords)\n",
    "\n",
    "class NewsletterGenerator:\n",
    "    \"\"\"Generates personalized newsletters based on user preferences.\"\"\"\n",
    "    \n",
    "    def __init__(self, feed_reader, article_analyzer):\n",
    "        self.feed_reader = feed_reader\n",
    "        self.article_analyzer = article_analyzer\n",
    "        self.user_personas = {\n",
    "            \"Alex Parker\": {\n",
    "                \"interests\": [\"AI\", \"cybersecurity\", \"blockchain\", \"startups\", \"programming\"],\n",
    "                \"sources\": [\"TechCrunch\", \"Wired\", \"Ars Technica\", \"MIT Technology Review\"],\n",
    "                \"categories\": [\"technology\", \"general\"]\n",
    "            },\n",
    "            \"Priya Sharma\": {\n",
    "                \"interests\": [\"global markets\", \"startups\", \"fintech\", \"cryptocurrency\", \"economics\"],\n",
    "                \"sources\": [\"Bloomberg\", \"Financial Times\", \"Forbes\", \"CoinDesk\"],\n",
    "                \"categories\": [\"finance\", \"technology\"]\n",
    "            },\n",
    "            \"Marco Rossi\": {\n",
    "                \"interests\": [\"football\", \"F1\", \"NBA\", \"Olympic sports\", \"esports\"],\n",
    "                \"sources\": [\"ESPN\", \"BBC Sport\", \"Sky Sports\"],\n",
    "                \"categories\": [\"sports\"]\n",
    "            },\n",
    "            \"Lisa Thompson\": {\n",
    "                \"interests\": [\"movies\", \"celebrity\", \"TV shows\", \"music\", \"books\"],\n",
    "                \"sources\": [\"Variety\", \"Rolling Stone\", \"Billboard\", \"Hollywood Reporter\"],\n",
    "                \"categories\": [\"entertainment\"]\n",
    "            },\n",
    "            \"David Martinez\": {\n",
    "                \"interests\": [\"space exploration\", \"AI\", \"biotech\", \"physics\", \"renewable energy\"],\n",
    "                \"sources\": [\"NASA\", \"Science Daily\", \"Nature\", \"Ars Technica\"],\n",
    "                \"categories\": [\"science\", \"technology\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def generate_newsletter(self, user_name, max_articles=10):\n",
    "        \"\"\"\n",
    "        Generates a personalized newsletter for a user.\n",
    "        \n",
    "        Args:\n",
    "            user_name: Name of the user to generate newsletter for\n",
    "            max_articles: Maximum number of articles to include in the newsletter\n",
    "            \n",
    "        Returns:\n",
    "            Markdown-formatted newsletter as a string\n",
    "        \"\"\"\n",
    "        # Check if user exists\n",
    "        if user_name not in self.user_personas:\n",
    "            return f\"Error: User '{user_name}' not found.\"\n",
    "        \n",
    "        user = self.user_personas[user_name]\n",
    "        \n",
    "        # Fetch articles\n",
    "        all_articles = self.feed_reader.fetch_articles(categories=user['categories'])\n",
    "        \n",
    "        # Score and rank articles based on user interests\n",
    "        scored_articles = []\n",
    "        for article in all_articles:\n",
    "            relevance_score = self.article_analyzer.calculate_relevance_score(article, user['interests'])\n",
    "            \n",
    "            # Boost score for preferred sources\n",
    "            source_match = any(preferred_source.lower() in article['source'].lower() for preferred_source in user['sources'])\n",
    "            if source_match:\n",
    "                relevance_score += 0.2\n",
    "                \n",
    "            # Cap the score at 1.0\n",
    "            relevance_score = min(relevance_score, 1.0)\n",
    "            \n",
    "            # Only include articles with some relevance\n",
    "            if relevance_score > 0.1:\n",
    "                article['relevance_score'] = relevance_score\n",
    "                scored_articles.append(article)\n",
    "        \n",
    "        # Sort by relevance score and limit to max_articles\n",
    "        ranked_articles = sorted(scored_articles, key=lambda x: x['relevance_score'], reverse=True)[:max_articles]\n",
    "        \n",
    "        # Group articles by category\n",
    "        categorized_articles = {}\n",
    "        for article in ranked_articles:\n",
    "            category = article['category']\n",
    "            if category not in categorized_articles:\n",
    "                categorized_articles[category] = []\n",
    "            categorized_articles[category].append(article)\n",
    "        \n",
    "        # Generate the newsletter in Markdown format\n",
    "        newsletter = self._format_newsletter(user_name, categorized_articles)\n",
    "        \n",
    "        return newsletter\n",
    "    \n",
    "    def _format_newsletter(self, user_name, categorized_articles):\n",
    "        \"\"\"Formats the newsletter in Markdown.\"\"\"\n",
    "        today = datetime.datetime.now().strftime('%A, %B %d, %Y')\n",
    "        \n",
    "        # Start with the header\n",
    "        newsletter = f\"# Personalized Newsletter for {user_name}\\n\\n\"\n",
    "        newsletter += f\"**Date:** {today}\\n\\n\"\n",
    "        \n",
    "        # Add top headlines section\n",
    "        newsletter += \"## 🔥 Top Headlines For You\\n\\n\"\n",
    "        \n",
    "        # Get the top 3 articles across all categories\n",
    "        all_articles = []\n",
    "        for category, articles in categorized_articles.items():\n",
    "            all_articles.extend(articles)\n",
    "        \n",
    "        top_articles = sorted(all_articles, key=lambda x: x['relevance_score'], reverse=True)[:3]\n",
    "        \n",
    "        for article in top_articles:\n",
    "            newsletter += f\"- **[{article['title']}]({article['link']})** - {article['source']}\\n\"\n",
    "        \n",
    "        newsletter += \"\\n\"\n",
    "        \n",
    "        # Add sections for each category\n",
    "        for category, articles in categorized_articles.items():\n",
    "            # Skip if the category has no articles\n",
    "            if not articles:\n",
    "                continue\n",
    "                \n",
    "            # Format the category name\n",
    "            category_name = category.capitalize()\n",
    "            \n",
    "            # Add category header with emoji\n",
    "            emoji_map = {\n",
    "                'technology': '💻',\n",
    "                'finance': '💰',\n",
    "                'sports': '🏆',\n",
    "                'entertainment': '🎬',\n",
    "                'science': '🔬',\n",
    "                'general': '🌎'\n",
    "            }\n",
    "            emoji = emoji_map.get(category, '📰')\n",
    "            \n",
    "            newsletter += f\"## {emoji} {category_name}\\n\\n\"\n",
    "            \n",
    "            # Add articles\n",
    "            for article in articles:\n",
    "                # Generate a short summary\n",
    "                summary = article['summary']\n",
    "                if len(summary) > 200:\n",
    "                    summary = summary[:197] + '...'\n",
    "                \n",
    "                newsletter += f\"### [{article['title']}]({article['link']})\\n\\n\"\n",
    "                newsletter += f\"**Source:** {article['source']}  \\n\"\n",
    "                newsletter += f\"**Published:** {article.get('published', 'Unknown date')}  \\n\\n\"\n",
    "                newsletter += f\"{summary}\\n\\n\"\n",
    "                newsletter += f\"[Read more]({article['link']})\\n\\n\"\n",
    "                newsletter += \"---\\n\\n\"\n",
    "        \n",
    "        # Add footer\n",
    "        newsletter += \"## 📬 Newsletter Preferences\\n\\n\"\n",
    "        newsletter += f\"This newsletter was curated based on your interests: {', '.join(self.user_personas[user_name]['interests'])}.\\n\\n\"\n",
    "        newsletter += \"Thank you for reading your personalized newsletter today!\\n\"\n",
    "        \n",
    "        return newsletter\n",
    "\n",
    "def main():\n",
    "    # Create instances of the classes\n",
    "    feed_reader = RSSFeedReader()\n",
    "    article_analyzer = ArticleAnalyzer()\n",
    "    newsletter_generator = NewsletterGenerator(feed_reader, article_analyzer)\n",
    "    \n",
    "    # Generate newsletters for all users\n",
    "    for user_name in newsletter_generator.user_personas.keys():\n",
    "        print(f\"Generating newsletter for {user_name}...\")\n",
    "        \n",
    "        # Generate the newsletter\n",
    "        newsletter = newsletter_generator.generate_newsletter(user_name)\n",
    "        \n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs('newsletters', exist_ok=True)\n",
    "        \n",
    "        # Save the newsletter to a file\n",
    "        filename = f\"newsletters/{user_name.replace(' ', '_').lower()}_newsletter.md\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(newsletter)\n",
    "        \n",
    "        print(f\"Newsletter saved to {filename}\")\n",
    "    \n",
    "    # Add this code to show the absolute path of the newsletters directory\n",
    "    absolute_path = os.path.abspath('newsletters')\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Newsletters are saved at: {absolute_path}\")\n",
    "    print(\"You can open this directory to view the generated newsletters.\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create a simple HTML index file to make it easier to view the newsletters\n",
    "    index_html = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>AI-Generated Newsletters</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }\n",
    "            h1 { color: #333; }\n",
    "            .newsletter-link { \n",
    "                display: block; \n",
    "                margin: 15px 0; \n",
    "                padding: 15px; \n",
    "                background-color: #f5f5f5; \n",
    "                border-radius: 5px;\n",
    "                text-decoration: none;\n",
    "                color: #333;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .newsletter-link:hover { background-color: #e0e0e0; }\n",
    "            .info { margin-top: 30px; padding: 15px; background-color: #e6f7ff; border-radius: 5px; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>AI-Generated Personalized Newsletters</h1>\n",
    "        <p>Click on a newsletter below to view it:</p>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add links to each newsletter\n",
    "    for user_name in newsletter_generator.user_personas.keys():\n",
    "        file_name = f\"{user_name.replace(' ', '_').lower()}_newsletter.md\"\n",
    "        index_html += f'<a href=\"{file_name}\" class=\"newsletter-link\">{user_name}\\'s Newsletter</a>\\n'\n",
    "    \n",
    "    index_html += \"\"\"\n",
    "        <div class=\"info\">\n",
    "            <p><strong>Note:</strong> These are Markdown (.md) files. If they open as plain text, you may want to use a Markdown viewer or editor for better formatting.</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the index.html file\n",
    "    with open('newsletters/index.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(index_html)\n",
    "    \n",
    "    print(f\"\\nAn index.html file has been created in the newsletters directory.\")\n",
    "    print(f\"You can open this file in a web browser to easily access all newsletters.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f8b6d-75b2-4956-afaf-e8889880fe06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
